# Datadog 모니터링 아키텍처 분석

> 작성일: 2025년 12월
> 목적: LLM 모니터링 프로젝트 참고용 아키텍처 분석

---

## 목차

1. [개요](#개요)
2. [데이터 수집 계층 (Agent)](#1-데이터-수집-계층-datadog-agent)
3. [데이터 처리 계층 (Pipeline)](#2-데이터-처리-계층-observability-pipelines)
4. [백엔드 저장 계층 (Storage)](#3-백엔드-저장-계층-storage-architecture)
5. [전체 아키텍처 요약](#4-전체-아키텍처-요약)
6. [LLM 모니터링 적용 시사점](#5-llm-모니터링-프로젝트-적용-시사점)
7. [참고 자료](#참고-자료)

---

## 개요

Datadog은 클라우드 기반 모니터링 및 분석 플랫폼으로, **하루 수조(trillion) 개의 데이터 포인트**를 처리합니다. 시스템은 크게 3개의 레이어로 구성됩니다:

| 계층 | 역할 | 핵심 기술 |
|------|------|-----------|
| **수집 (Collection)** | 호스트/컨테이너에서 메트릭, 로그, 트레이스 수집 | Datadog Agent |
| **처리 (Processing)** | 데이터 변환, 필터링, 라우팅 | Observability Pipelines |
| **저장 (Storage)** | 시계열 데이터 및 이벤트 저장/쿼리 | Monocle, Husky, RocksDB |

---

## 1. 데이터 수집 계층 (Datadog Agent)

### 1.1 핵심 컴포넌트

Datadog Agent는 호스트에 설치되는 경량 소프트웨어로, 다음 컴포넌트로 구성됩니다:

| 컴포넌트 | 역할 | 수집 주기 |
|----------|------|-----------|
| **Collector** | 시스템/애플리케이션 메트릭 수집 | 15초 |
| **Forwarder** | HTTPS로 Datadog 백엔드에 데이터 전송 | 실시간 |
| **DogStatsD** | 애플리케이션 코드에서 전송하는 커스텀 메트릭 집계 | 실시간 |
| **APM Agent** | 분산 트레이스 수집 | 실시간 |
| **Process Agent** | 실시간 프로세스/컨테이너 정보 수집 | 10초 (기본) / 2초 (실시간 뷰) |

### 1.2 Agent 내부 데이터 흐름

```
┌─────────────────────────────────────────────────────────────────┐
│                      Datadog Agent                               │
│                                                                  │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────────┐   │
│  │  Collector   │    │  DogStatsD   │    │   APM Agent      │   │
│  │ (시스템메트릭) │    │ (커스텀메트릭) │    │   (트레이스)      │   │
│  └──────┬───────┘    └──────┬───────┘    └────────┬─────────┘   │
│         │                   │                     │              │
│         └───────────────────┼─────────────────────┘              │
│                             │                                    │
│                    ┌────────▼────────┐                          │
│                    │    Forwarder    │                          │
│                    │  (버퍼링 & 전송)  │                          │
│                    └────────┬────────┘                          │
│                             │                                    │
└─────────────────────────────┼────────────────────────────────────┘
                              │ HTTPS
                              ▼
                     Datadog Cloud Platform
```

### 1.3 배포 아키텍처 유형

#### Self-Hosted 환경
```
┌─────────────────────────────────────┐
│           Database Host             │
│  ┌─────────────┐  ┌──────────────┐  │
│  │  Database   │  │ Datadog Agent│  │
│  │  (MySQL,    │◄─│  - DB 메트릭  │  │
│  │   Postgres) │  │  - 시스템메트릭│  │
│  └─────────────┘  └──────────────┘  │
└─────────────────────────────────────┘
```
- Agent가 DB 호스트에 직접 설치
- OS 레벨 메트릭 + DB 메트릭 동시 수집

#### Cloud-Managed 환경 (AWS RDS, Aurora 등)
```
┌──────────────────┐        ┌──────────────────┐
│  RDS Instance    │        │   Agent Host     │
│  (관리형 DB)      │◄──────│  Datadog Agent   │
└──────────────────┘        └──────────────────┘
         │                           │
         │                           │
         ▼                           ▼
┌──────────────────────────────────────────────┐
│          Datadog Cloud Platform              │
│  (CloudWatch 연동으로 추가 메트릭 수집)         │
└──────────────────────────────────────────────┘
```
- 별도 호스트에 Agent 설치 후 관리형 DB에 연결
- 클라우드 프로바이더 연동으로 시스템 메트릭 수집

#### Kubernetes 환경
```
┌─────────────────────────────────────────────────────────────────┐
│                    Kubernetes Cluster                            │
│                                                                  │
│  ┌────────────────────────────────────────────────────────────┐ │
│  │                   Cluster Agent (Deployment)                │ │
│  │  - K8s API 서버 부하 경감 (프록시 역할)                        │ │
│  │  - 클러스터 레벨 메타데이터 수집                               │ │
│  │  - 10초마다 Node Agent에 설정 분배                           │ │
│  └────────────────────────────────────────────────────────────┘ │
│                              │                                   │
│           ┌──────────────────┼──────────────────┐               │
│           ▼                  ▼                  ▼               │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐         │
│  │ Node Agent  │    │ Node Agent  │    │ Node Agent  │         │
│  │ (DaemonSet) │    │ (DaemonSet) │    │ (DaemonSet) │         │
│  │             │    │             │    │             │         │
│  │ Pod1  Pod2  │    │ Pod3  Pod4  │    │ Pod5  Pod6  │         │
│  └─────────────┘    └─────────────┘    └─────────────┘         │
│      Node 1             Node 2             Node 3              │
└─────────────────────────────────────────────────────────────────┘
```

**Cluster Agent 주요 기능:**
- Kubernetes API 서버 부하 분산
- 클러스터 체크의 동적 분배
- 노드 장애 시 자동 재분배 (10초 주기)

---

## 2. 데이터 처리 계층 (Observability Pipelines)

### 2.1 개요

Observability Pipelines는 **고객 인프라 내에서 실행**되며, 데이터가 외부로 전송되기 전에 처리합니다.

```
┌─────────────────────────────────────────────────────────────────┐
│                  Observability Pipelines Worker                  │
│                                                                  │
│  ┌──────────┐    ┌──────────────────────┐    ┌──────────────┐   │
│  │  Source  │───►│     Processors       │───►│ Destinations │   │
│  │          │    │                      │    │              │   │
│  │ • Agent  │    │ • Transform (변환)    │    │ • Datadog    │   │
│  │ • Syslog │    │ • Filter (필터링)     │    │ • Splunk     │   │
│  │ • HTTP   │    │ • Sample (샘플링)     │    │ • S3         │   │
│  │ • Kafka  │    │ • Aggregate (집계)    │    │ • Elasticsearch│ │
│  └──────────┘    │ • Redact (민감정보)   │    └──────────────┘   │
│                  │ • Generate Metrics   │                       │
│                  └──────────────────────┘                       │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 주요 기능

| 기능 | 설명 | 사용 사례 |
|------|------|----------|
| **Log Volume Control** | 불필요한 로그 필터링/샘플링 | 비용 절감 |
| **Dual Shipping** | 동일 데이터를 여러 목적지로 전송 | 마이그레이션, 백업 |
| **Sensitive Data Redaction** | PII, 비밀번호 등 민감정보 마스킹 | 컴플라이언스 |
| **Generate Metrics from Logs** | 로그에서 메트릭 추출 | 실시간 분석 |
| **Archive to S3** | 장기 보관용 아카이빙 | 감사, 규정 준수 |

### 2.3 확장성

```
                    ┌─────────────────┐
                    │  Load Balancer  │
                    └────────┬────────┘
                             │
         ┌───────────────────┼───────────────────┐
         │                   │                   │
         ▼                   ▼                   ▼
┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐
│ Pipeline Worker │ │ Pipeline Worker │ │ Pipeline Worker │
│    Instance 1   │ │    Instance 2   │ │    Instance 3   │
└─────────────────┘ └─────────────────┘ └─────────────────┘
```

- 각 Worker 인스턴스는 **독립적으로 동작** (Stateless)
- 로드밸런서로 **수평 확장** 가능
- CPU/메모리 사용량, 처리량 모니터링 제공

---

## 3. 백엔드 저장 계층 (Storage Architecture)

### 3.1 전체 데이터 흐름

```
┌──────────────────────────────────────────────────────────────────┐
│                    Datadog Cloud Platform                         │
│                                                                   │
│  ┌──────────────┐                                                │
│  │ Load Balancer│                                                │
│  └──────┬───────┘                                                │
│         │                                                        │
│         ▼                                                        │
│  ┌──────────────┐         ┌─────────────────────────────────┐   │
│  │Metrics Intake│────────►│           Kafka                 │   │
│  │              │         │     (Message Broker)            │   │
│  └──────────────┘         └──────────────┬──────────────────┘   │
│                                          │                       │
│                    ┌─────────────────────┼─────────────────────┐ │
│                    │                     │                     │ │
│                    ▼                     ▼                     ▼ │
│           ┌──────────────┐      ┌──────────────┐      ┌────────┐│
│           │   Monocle    │      │   RocksDB    │      │ Husky  ││
│           │  (Metrics)   │      │ (Tag Index)  │      │(Events)││
│           └──────────────┘      └──────────────┘      └────────┘│
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
```

### 3.2 Kafka의 역할

Kafka는 **내구성 있는 메시지 브로커**로서 다음 역할을 수행:

- 데이터 수집과 저장의 **디커플링**
- 여러 서비스가 **동일 데이터 스트림을 독립적으로 소비**
- 분석, 인덱싱, 장기 보관 등 **다양한 목적으로 활용**

### 3.3 Monocle - 실시간 시계열 데이터베이스

Datadog의 6세대 RTDB(Real-Time Database)로, Rust로 작성되었습니다.

**주요 특징:**

| 특성 | 설명 |
|------|------|
| **언어** | Rust (성능 및 안정성) |
| **아키텍처** | LSM Tree (Log-Structured Merge Tree) |
| **동시성 모델** | Thread-per-core (Shared-nothing) |
| **성능 향상** | 이전 세대 대비 60x 쓰기 성능, 5x 쿼리 성능 |

**데이터 구조:**
```
Timeseries DB: <timeseries_id, timestamp, float64>

예시:
┌──────────────┬─────────────────────┬───────────┐
│ timeseries_id│     timestamp       │   value   │
├──────────────┼─────────────────────┼───────────┤
│     12345    │ 2025-12-05 10:00:00 │   42.5    │
│     12345    │ 2025-12-05 10:00:15 │   43.2    │
│     12346    │ 2025-12-05 10:00:00 │   128.0   │
└──────────────┴─────────────────────┴───────────┘
```

### 3.4 RocksDB - 태그 인덱싱

시계열 ID와 태그의 매핑을 관리합니다.

**3개의 RocksDB 인스턴스:**

| DB | 용도 |
|----|------|
| **Tagsets** | 태그 조합 저장 |
| **Metrics** | 메트릭 메타데이터 |
| **Indexes** | 태그 → 시계열 ID 매핑 |

```
태그 예시:
  host:web-server-01
  env:production
  service:api-gateway

쿼리: env:production AND service:api-gateway
  → 해당하는 모든 timeseries_id 반환
```

### 3.5 Husky - 이벤트 스토어 (3세대)

로그, 트레이스 등 이벤트 데이터를 저장하는 분산 컬럼 스토어입니다.

**아키텍처 특징:**
- **Unbundled**: 쓰기/읽기/압축 워크로드 분리
- **Schemaless**: 유연한 스키마
- **Vectorized**: 벡터화된 쿼리 처리
- **Object Storage 기반**: AWS S3 활용

```
┌─────────────────────────────────────────────────────────────────┐
│                         Husky Architecture                       │
│                                                                  │
│  ┌──────────┐         ┌──────────┐         ┌──────────┐        │
│  │ Writers  │         │ Readers  │         │Compactors│        │
│  │          │         │          │         │          │        │
│  │ Kafka →  │         │ 쿼리 처리 │         │ 데이터    │        │
│  │ S3 업로드│         │ & 반환   │         │ 압축/정리 │        │
│  └────┬─────┘         └────┬─────┘         └────┬─────┘        │
│       │                    │                    │               │
│       └────────────────────┼────────────────────┘               │
│                            │                                    │
│                   ┌────────▼────────┐                          │
│                   │  FoundationDB   │                          │
│                   │ (Metadata Store)│                          │
│                   └────────┬────────┘                          │
│                            │                                    │
│                   ┌────────▼────────┐                          │
│                   │     AWS S3      │                          │
│                   │  (Blob Storage) │                          │
│                   └─────────────────┘                          │
└─────────────────────────────────────────────────────────────────┘
```

**역할 분리의 장점:**
- 각 워크로드를 **독립적으로 스케일링**
- Writers 부하 ↑ → Writers만 확장
- 읽기 지연 ↓ → Readers만 확장

---

## 4. 전체 아키텍처 요약

```
┌─────────────────────────────────────────────────────────────────────────┐
│                            사용자 인프라                                  │
│                                                                         │
│   ┌──────────┐   ┌──────────┐   ┌──────────────────────────────────┐   │
│   │  Host    │   │Container │   │    Observability Pipelines       │   │
│   │  Agent   │   │  Agent   │   │         Worker                   │   │
│   │          │   │          │   │                                  │   │
│   │ •Metrics │   │ •Metrics │   │  Source → Processor → Destination│   │
│   │ •Logs    │   │ •Logs    │   │                                  │   │
│   │ •Traces  │   │ •Traces  │   └───────────────┬──────────────────┘   │
│   └────┬─────┘   └────┬─────┘                   │                       │
│        │              │                         │                       │
└────────┼──────────────┼─────────────────────────┼───────────────────────┘
         │              │                         │
         └──────────────┴─────────────────────────┘
                        │
                        │ HTTPS (암호화된 전송)
                        ▼
┌─────────────────────────────────────────────────────────────────────────┐
│                       Datadog Cloud Platform                             │
│                                                                         │
│   ┌───────────────────────────────────────────────────────────────────┐ │
│   │                        Intake Layer                                │ │
│   │   ┌──────────────┐    ┌──────────────┐    ┌──────────────┐       │ │
│   │   │Load Balancer │───►│Metrics Intake│───►│    Kafka     │       │ │
│   │   └──────────────┘    └──────────────┘    └──────┬───────┘       │ │
│   └──────────────────────────────────────────────────┼────────────────┘ │
│                                                      │                   │
│   ┌──────────────────────────────────────────────────┼────────────────┐ │
│   │                     Storage Layer                │                 │ │
│   │                                                  │                 │ │
│   │        ┌─────────────────────────────────────────┤                │ │
│   │        │                    │                    │                │ │
│   │        ▼                    ▼                    ▼                │ │
│   │   ┌─────────┐         ┌─────────┐         ┌─────────┐            │ │
│   │   │ Monocle │         │ RocksDB │         │  Husky  │            │ │
│   │   │ (RTDB)  │         │ (Index) │         │ (Events)│            │ │
│   │   │         │         │         │         │         │            │ │
│   │   │ Metrics │         │  Tags   │         │Logs/Trace│           │ │
│   │   └─────────┘         └─────────┘         └─────────┘            │ │
│   └───────────────────────────────────────────────────────────────────┘ │
│                                                                         │
│   ┌───────────────────────────────────────────────────────────────────┐ │
│   │                    Query & Visualization Layer                     │ │
│   │                                                                    │ │
│   │   ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐        │ │
│   │   │ Dashboard │ │  Monitors │ │    APM    │ │Log Explorer│       │ │
│   │   └───────────┘ └───────────┘ └───────────┘ └───────────┘        │ │
│   │                                                                    │ │
│   │   ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐        │ │
│   │   │  Alerts   │ │ Notebooks │ │  SLOs     │ │  Profiler │        │ │
│   │   └───────────┘ └───────────┘ └───────────┘ └───────────┘        │ │
│   └───────────────────────────────────────────────────────────────────┘ │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 5. LLM 모니터링 프로젝트 적용 시사점

Datadog 아키텍처에서 LLM 모니터링 프로젝트에 적용할 수 있는 핵심 패턴:

### 5.1 Agent 기반 데이터 수집

```
┌─────────────────────────────────────────────────┐
│              LLM Application                     │
│                                                 │
│   ┌─────────────┐      ┌──────────────────┐    │
│   │ LLM Client  │─────►│ Monitoring Agent │    │
│   │ (API 호출)   │      │ • Request 로깅   │    │
│   └─────────────┘      │ • Token 카운팅   │    │
│                        │ • 지연시간 측정   │    │
│                        └────────┬─────────┘    │
│                                 │              │
└─────────────────────────────────┼──────────────┘
                                  │
                                  ▼
                         Monitoring Server
```

**적용 포인트:**
- 경량 에이전트/SDK로 LLM API 호출 인터셉트
- 비동기 전송으로 애플리케이션 성능 영향 최소화
- 네트워크 장애 시 로컬 버퍼링

### 5.2 메시지 큐를 통한 디커플링

```
Agent → Kafka/Redis → Storage
```

**적용 포인트:**
- 수집과 저장을 분리하여 각각 독립적으로 확장
- 피크 트래픽 시 버퍼 역할
- 다양한 소비자 (분석, 알림, 아카이빙)

### 5.3 목적에 맞는 저장소 분리

| 데이터 유형 | 저장소 추천 | 용도 |
|------------|------------|------|
| **메트릭** (Token 사용량, 지연시간) | TimescaleDB, InfluxDB | 시계열 쿼리, 대시보드 |
| **로그** (Request/Response) | Elasticsearch, S3 | 전문 검색, 아카이빙 |
| **메타데이터** (사용자, 프로젝트) | PostgreSQL | 관계형 쿼리 |

### 5.4 핵심 설계 원칙

| 원칙 | Datadog 적용 | LLM 모니터링 적용 |
|------|-------------|------------------|
| **관심사 분리** | 수집/처리/저장/쿼리 분리 | 동일 적용 |
| **수평 확장** | Stateless Worker | 동일 적용 |
| **데이터 신선도** | 15초 주기 수집 | API 호출별 실시간 |
| **고가용성** | 다중 AZ, 복제 | 필요시 적용 |

---

## 참고 자료

### Datadog 공식 문서
- [Agent Architecture](https://docs.datadoghq.com/agent/architecture/)
- [Database Monitoring Architecture](https://docs.datadoghq.com/database_monitoring/architecture/)
- [Observability Pipelines](https://docs.datadoghq.com/observability_pipelines/)

### Datadog Engineering Blog
- [Timeseries Indexing at Scale](https://www.datadoghq.com/blog/engineering/timeseries-indexing-at-scale/)
- [Rust Timeseries Engine (Monocle)](https://www.datadoghq.com/blog/engineering/rust-timeseries-engine/)
- [Introducing Husky](https://www.datadoghq.com/blog/engineering/introducing-husky/)
- [Building Highly Reliable Data Pipelines](https://www.datadoghq.com/blog/engineering/highly-reliable-data-pipelines/)

### 외부 분석
- [How Datadog Built a Custom Database - ByteByteGo](https://blog.bytebytego.com/p/how-datadog-built-a-custom-database)
- [Datadog Creates Scalable Data Ingestion Architecture - InfoQ](https://www.infoq.com/news/2023/06/datadog-husky-data-ingestion/)
- [Datadog: A Real-Time Metrics Database - InfoQ](https://www.infoq.com/presentations/datadog-metrics-db/)
